{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pip install torchsummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project 6: U-Net and Autoencoders\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# Global noise values\n",
    "MILD = .1\n",
    "MEDIUM = .25\n",
    "SEVERE = .4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "        Our UNet is a neural network that reduces an images to core features\n",
    "        (while reducing the size of the image and increasing the channels),\n",
    "        and then increases it back to its original size.\n",
    "\n",
    "        Since the input images from MNIST are size 28x28, we did not want to\n",
    "        fuclass UNet(nn.Module):\n",
    "    def __init__(self, channels=3, output_classes=10):\n",
    "        super().__init__()\n",
    "        self.loss_func = nn.MSELoss()\n",
    "        self.ConvLayer1 = self.ConvLayer(channels, 20, 3)\n",
    "        self.MaxPool = nn.MaxPool2d(2)\n",
    "        self.ConvLayer2 = self.ConvLayer(20, 40, 3)\n",
    "        self.ConvLayer3 = self.ConvLayer(40, 80, 3)\n",
    "        self.TransposeLayer1 = self.TransposeConvLayer(80, 40, 2)\n",
    "        self.ConvLayer4 = self.ConvLayer(80, 40, 3)\n",
    "        self.TransposeLayer2 = self.TransposeConvLayer(40, 20, 2)\n",
    "        self.ConvLayer5 = self.ConvLayer(40, 20, 3)\n",
    "        self.ConvOneByOne = nn.Conv2d(20, 3, kernel_size=1)  # Output should have 3 channelslly replicate the original UNet. Because we are simplifying the problem,\n",
    "        a reduction in channel dimension makes sense here, as well as a reduction\n",
    "        in total layers.\n",
    "\n",
    "        We decided our architecture would look like this:\n",
    "          - 1 CL (Convolutional Layer) followed by a Max Pool Layer 2 times, then\n",
    "          - A bottom CL followed by a TCL (Transpose CL) 2 times, followed by\n",
    "          - Two CL (the last one reducing the dimension size back to 1)\n",
    "\n",
    "        The image gets reduced from a size of 28x28 -> 14x14 -> 7x7, the channel\n",
    "        size gets increased from 1 -> 20 -> 40 -> 80, and then the size scales\n",
    "        back up and the channel size scales back down.\n",
    "\n",
    "        One key aspect of the UNet is that before the MaxPool layers, a copy of\n",
    "        the outputs get saved so it can be concatenated later in the re-scaling side.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels=3, output_classes=10):\n",
    "        super().__init__()\n",
    "        self.loss_func = nn.MSELoss()\n",
    "        self.ConvLayer1 = self.ConvLayer(channels, 20, 3)\n",
    "        self.MaxPool = nn.MaxPool2d(2)\n",
    "        self.ConvLayer2 = self.ConvLayer(20, 40, 3)\n",
    "        self.ConvLayer3 = self.ConvLayer(40, 80, 3)\n",
    "        self.TransposeLayer1 = self.TransposeConvLayer(80, 40, 2)\n",
    "        self.ConvLayer4 = self.ConvLayer(80, 40, 3)\n",
    "        self.TransposeLayer2 = self.TransposeConvLayer(40, 20, 2)\n",
    "        self.ConvLayer5 = self.ConvLayer(40, 20, 3)\n",
    "        self.ConvOneByOne = nn.Conv2d(20, 3, kernel_size=1)  # Output should have 3 channels\n",
    "\n",
    "    # Remainder of the class stays the same\n",
    "\n",
    "\n",
    "    def ConvLayer(self, in_ch, out_ch, kernel_size=3):\n",
    "        sequence = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size, 1, 1),\n",
    "            nn.ReLU())\n",
    "        return sequence\n",
    "\n",
    "    def TransposeConvLayer(self, in_ch, out_ch, kernel_size=2):\n",
    "        sequence = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_ch, out_ch, kernel_size, 2),\n",
    "            nn.ReLU())\n",
    "        return sequence\n",
    "\n",
    "    def forward(self, x):\n",
    "        a = self.ConvLayer1(x)\n",
    "        x = a\n",
    "        b = self.ConvLayer2(self.MaxPool(x))\n",
    "        x = b\n",
    "        x = self.TransposeLayer1(self.ConvLayer3(self.MaxPool(x)))\n",
    "        x = self.TransposeLayer2(self.ConvLayer4(torch.cat([b,x], dim=1)))\n",
    "        return self.ConvOneByOne(self.ConvLayer5(torch.cat([a,x], dim=1)))\n",
    "\n",
    "    def num_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "# Create a UNet instance and visualize parameter grid\n",
    "unet = UNet().to(device)\n",
    "print(f\"Total parameters for UNet: {unet.num_parameters()}\")\n",
    "summary(unet, (3, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "        Our Autoencoder network is essentially the same thing as our UNet.\n",
    "        However, we do not employ skip connections (we don't save the output\n",
    "        of the Convolutional Layers in order to do concatenations later).\n",
    "\n",
    "        The autoencoder employs the same architecture and size reduction/\n",
    "        scaling sizes as our previous UNet architecture.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels=3, output_classes=10):\n",
    "        super().__init__()\n",
    "        self.loss_func = nn.MSELoss()\n",
    "        self.layers = nn.Sequential(\n",
    "            self.ConvLayer(channels, 20, 3),\n",
    "            nn.MaxPool2d(2),\n",
    "            self.ConvLayer(20, 40, 3),\n",
    "            nn.MaxPool2d(2),\n",
    "            self.ConvLayer(40, 80, 3),\n",
    "            self.TransposeConvLayer(80, 40, 2),\n",
    "            self.TransposeConvLayer(40, 20, 2),\n",
    "            nn.Conv2d(20, 3, kernel_size=1)  # Output should have 3 channels\n",
    "        )\n",
    "\n",
    "\n",
    "    # ConvLayer and TransposeConvLayer methods remain the same\n",
    "\n",
    "    def ConvLayer(self, in_ch, out_ch, kernel_size=3):\n",
    "        return nn.Sequential(nn.Conv2d(in_ch, out_ch, kernel_size, 1, 1),\n",
    "                             nn.ReLU())\n",
    "\n",
    "    def TransposeConvLayer(self, in_ch, out_ch, kernel_size=2):\n",
    "        return nn.Sequential(nn.ConvTranspose2d(in_ch, in_ch, kernel_size, 2),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Conv2d(in_ch, out_ch, 3, 1, 1),\n",
    "                             nn.ReLU())\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def num_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "\n",
    "# Create an autoencoder instance and visualize parameter grid\n",
    "autoencoder = Autoencoder().to(device)\n",
    "print(f\"Total parameters for Autoencoder: {autoencoder.num_parameters()}\")\n",
    "summary(autoencoder, (3, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Add this import at the beginning of your script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def noisy_generator(batches, noise_type='salt_and_pepper'):\n",
    "    for batch_x, batch_y in batches:\n",
    "        if noise_type == 'salt_and_pepper':\n",
    "            # Generate salt and pepper noise\n",
    "            salt_vs_pepper = 0.3\n",
    "            noise = np.random.choice([0, 1, 2], size=batch_x.shape, p=[1 - salt_vs_pepper, salt_vs_pepper / 2., salt_vs_pepper / 2.])\n",
    "            salt_mask = noise == 1\n",
    "            pepper_mask = noise == 2\n",
    "            \n",
    "            # Add salt noise\n",
    "            salt_intensity = 1\n",
    "            batch_noisy = batch_x.copy()\n",
    "            batch_noisy[salt_mask] = salt_intensity\n",
    "            \n",
    "            # Add pepper noise\n",
    "            pepper_intensity = 0\n",
    "            batch_noisy[pepper_mask] = pepper_intensity\n",
    "        elif noise_type == 'gaussian':\n",
    "            # Add Gaussian noise\n",
    "            mean = 0.\n",
    "            std = 0.5\n",
    "            batch_noisy = batch_x + np.random.normal(mean, std, size=batch_x.shape)\n",
    "            batch_noisy = np.clip(batch_noisy, 0., 1.)\n",
    "        elif noise_type == 'rayleigh':\n",
    "            # Add Rayleigh noise\n",
    "            scale = 0.1\n",
    "            noise = np.random.rayleigh(scale, size=batch_x.shape)\n",
    "            batch_noisy = batch_x + noise\n",
    "            batch_noisy = np.clip(batch_noisy, 0., 1.)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid noise type. Choose from 'salt_and_pepper', 'gaussian', or 'rayleigh'.\")\n",
    "\n",
    "        yield (batch_noisy, batch_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Resize\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import tensorflow as tf\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=0.5):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "class AddSaltAndPepperNoise(object):\n",
    "    def __init__(self, prob=0.4):\n",
    "        self.prob = prob\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        noisy_image = tensor.clone()\n",
    "        salt_pepper = torch.rand_like(tensor)\n",
    "        noisy_image[salt_pepper < self.prob / 2] = 0.0\n",
    "        noisy_image[salt_pepper > 1 - self.prob / 2] = 1.0\n",
    "        return noisy_image\n",
    "\n",
    "class AddRayleighNoise(object):\n",
    "    def __init__(self, scale=0.3):\n",
    "        self.scale = scale\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        noise = torch.randn_like(tensor, dtype=torch.float) * self.scale\n",
    "        noisy_image = tensor + noise\n",
    "        noisy_image = torch.clamp(noisy_image, 0, 1)\n",
    "        return noisy_image\n",
    "class AddSpeckleNoise(object):\n",
    "    def __init__(self, mean=0., std=0.5):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        noise = tf.random.normal(tf.shape(tensor), mean=self.mean, stddev=self.std, dtype=tf.float32)\n",
    "        noisy_tensor = tensor + tensor * noise\n",
    "        return noisy_tensor\n",
    "\n",
    "mu=0.2\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, noise_type='gaussian'):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.noise_type = 'gaussian'\n",
    "\n",
    "        for root, _, files in os.walk(data_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\".png\"):\n",
    "                    self.image_paths.append(os.path.join(root, file))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Add noise to the image here based on the specified noise type\n",
    "        if self.noise_type == 'gaussian':\n",
    "            noise_func = AddGaussianNoise()\n",
    "        elif self.noise_type == 'salt_and_pepper':\n",
    "            noise_func = AddSaltAndPepperNoise()\n",
    "        elif self.noise_type == 'rayleigh':\n",
    "            noise_func = AddRayleighNoise()\n",
    "        elif self.noise_type == 'speckle':\n",
    "            # Add Gaussian Noise\n",
    "            noise_func = AddSpeckleNoise(std=0.5)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported noise type\")\n",
    "\n",
    "        noisy_image = noise_func(image)\n",
    "        \n",
    "        return noisy_image, image  # Return both the noisy image and the clean image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize images to 32x32 (adjust as needed)\n",
    "    transforms.ToTensor()         # Convert images to tensors\n",
    "])\n",
    "\n",
    "data_dir = \"/kaggle/input/dataset-explo/bsds500/images/train/all\"\n",
    "custom_dataset = CustomDataset(data_dir, transform=transform)\n",
    "\n",
    "# Check the length of the dataset\n",
    "print(len(custom_dataset))\n",
    "\n",
    "# Create a DataLoader for your custom dataset\n",
    "batch_size = 32\n",
    "custom_dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Train function for both models\n",
    "def train(model, dataloader, epochs, optimizer):\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for noisy_image, clean_image in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            input_data = noisy_image.to(device)\n",
    "            output_data = model(input_data)\n",
    "            loss = criterion(output_data, clean_image.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * input_data.size(0)\n",
    "        epoch_loss /= len(dataloader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Example usage\n",
    "num_epochs = 100\n",
    "lr = 0.002\n",
    "u_net = UNet().to(device)\n",
    "autoencoder = Autoencoder().to(device)\n",
    "u_opt = Adam(u_net.parameters(), lr=lr)\n",
    "auto_opt = Adam(autoencoder.parameters(), lr=lr)\n",
    "\n",
    "# Train U-Net\n",
    "train(u_net, custom_dataloader, num_epochs, u_opt)\n",
    "\n",
    "# Train Autoencoder\n",
    "train(autoencoder, custom_dataloader, num_epochs, auto_opt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Resize\n",
    "\n",
    "resize_transform = Resize((256, 256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create an instance of your custom dataset\n",
    "test_data_dir = '/kaggle/input/aaaaaaaaaaa/owndataset/all'\n",
    "test_dataset = CustomDataset(test_data_dir, transform=transforms.Compose([resize_transform, transforms.ToTensor()]))\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Create an instance of your custom dataset\n",
    "test_data_dir = \"/kaggle/input/aaaaaaaaaaa/owndataset/all\"\n",
    "test_dataset = CustomDataset(test_data_dir, transform=transforms.Compose([resize_transform, transforms.ToTensor()]))\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def test_model(model, model2, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    model2.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient tracking during inference\n",
    "        for i, (noisy_images, clean_images) in enumerate(dataloader):\n",
    "            input_data = noisy_images.to(device)\n",
    "            output_data = model(input_data)\n",
    "            output_data2 = model2(input_data)\n",
    "\n",
    "            for j in range(len(noisy_images)):  # Iterate over each image in the batch\n",
    "                # Calculate PSNR and SSIM for model 1\n",
    "                psnr_value = psnr(clean_images[j].permute(1, 2, 0).cpu().numpy(), output_data[j].permute(1, 2, 0).cpu().numpy())\n",
    "                ssim_value = ssim(clean_images[j].permute(1, 2, 0).cpu().numpy(), output_data[j].permute(1, 2, 0).cpu().numpy(), win_size=3, data_range=1, multichannel=True)\n",
    "                print(f\"Model 1 - PSNR: {psnr_value:.4f}, SSIM: {ssim_value:.4f}\")\n",
    "\n",
    "                # Calculate PSNR and SSIM for model 2\n",
    "                psnr_value2 = psnr(clean_images[j].permute(1, 2, 0).cpu().numpy(), output_data2[j].permute(1, 2, 0).cpu().numpy())\n",
    "                ssim_value2 = ssim(clean_images[j].permute(1, 2, 0).cpu().numpy(), output_data2[j].permute(1, 2, 0).cpu().numpy(), win_size=3, data_range=1, multichannel=True)\n",
    "                print(f\"Model 2 - PSNR: {psnr_value2:.4f}, SSIM: {ssim_value2:.4f}\")\n",
    "\n",
    "                # Display images and metrics (you can add your metric calculation here)\n",
    "                # For example, displaying the images\n",
    "                input_image = noisy_images[j].permute(1, 2, 0).cpu().numpy()\n",
    "                denoised_image = output_data[j].permute(1, 2, 0).cpu().numpy()\n",
    "                denoised_image2 = output_data2[j].permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "                fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "                axs[0].imshow(input_image)\n",
    "                axs[0].set_title(\"Noisy Image\")\n",
    "                axs[0].axis(\"off\")\n",
    "                axs[1].imshow(denoised_image)\n",
    "                axs[1].set_title(\"Denoised Image (Model 1)\")\n",
    "                axs[1].axis(\"off\")\n",
    "                axs[2].imshow(denoised_image2)\n",
    "                axs[2].set_title(\"Denoised Image (Model 2)\")\n",
    "                axs[2].axis(\"off\")\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "test_model(u_net, autoencoder, test_dataloader)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
