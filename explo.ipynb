{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "P_MODELSAVE = 'saved_models'\n",
    "P_LOGS = 'logs'\n",
    "P_IMGSAVE = 'saved_images'\n",
    "\n",
    "dirs = [P_MODELSAVE, P_LOGS, P_IMGSAVE]\n",
    "\n",
    "for d in dirs:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "        \n",
    "\n",
    "dataset_path = '/kaggle/input/dataset-explo/bsds500/images'\n",
    "batch_size = 20\n",
    "epochs = 150\n",
    "input_shape = (256, 256)\n",
    "noise_factor = 1\n",
    "\n",
    "\n",
    "# the path to save the weight of the model\n",
    "# saved_weight = os.path.join(P_MODELSAVE, 'dataweights.{epoch:02d}-{val_acc:.2f}.hdf5')\n",
    "# saved_weight = os.path.join(P_MODELSAVE, 'dataweights.{epoch:02d}-{val_acc:.2f}.hdf5.keras')\n",
    "saved_weight = os.path.join(P_MODELSAVE, 'dataweights.{epoch:02d}-{val_accuracy:.2f}.hdf5.keras')\n",
    "\n",
    "\n",
    "\n",
    "from PIL import Image as pil_image\n",
    "\n",
    "def random_crop(img, random_crop_size):\n",
    "    width, height = img.size # PIL format\n",
    "    dx, dy = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img.crop((x, y, x+dx, y+dy))\n",
    "\n",
    "\n",
    "def load_img_extended(path, grayscale=False, color_mode='rgb', target_size=None,\n",
    "                      interpolation='nearest'):\n",
    "    if grayscale is True:\n",
    "        warnings.warn('grayscale is deprecated. Please use '\n",
    "                      'color_mode = \"grayscale\"')\n",
    "        color_mode = 'grayscale'\n",
    "    if pil_image is None:\n",
    "        raise ImportError('Could not import PIL.Image. '\n",
    "                          'The use of `array_to_img` requires PIL.')\n",
    "    img = pil_image.open(path)\n",
    "    if color_mode == 'grayscale':\n",
    "        if img.mode != 'L':\n",
    "            img = img.convert('L')\n",
    "    elif color_mode == 'rgba':\n",
    "        if img.mode != 'RGBA':\n",
    "            img = img.convert('RGBA')\n",
    "    elif color_mode == 'rgb':\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "    else:\n",
    "        raise ValueError('color_mode must be \"grayscale\", \"rbg\", or \"rgba\"')\n",
    "    \n",
    "    if target_size is not None:\n",
    "        width_height_tuple = (target_size[1], target_size[0])\n",
    "        if img.size != width_height_tuple:\n",
    "            img = random_crop(img, width_height_tuple) # here comes the magic\n",
    "    return img\n",
    "\n",
    "\n",
    "keras.preprocessing.image.load_img = load_img_extended\n",
    "\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "data_gen_args = dict(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     brightness_range=[0.5, 1.2],\n",
    "#     shear_range=0.01,\n",
    "#     horizontal_flip=True,\n",
    "    rescale=1/255,\n",
    "    fill_mode='reflect',\n",
    "    data_format='channels_last')\n",
    "\n",
    "data_flow_args = dict(\n",
    "    target_size=input_shape,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input') # Since we want to reconstruct the input\n",
    "\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        noise = tf.random.normal(tf.shape(tensor), mean=self.mean, stddev=self.std, dtype=tf.float32)\n",
    "        return tensor + noise\n",
    "\n",
    "class AddSaltAndPepperNoise(object):\n",
    "    def __init__(self, prob=0.2):\n",
    "        self.prob = prob\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        salt_pepper = tf.random.uniform(tf.shape(tensor), 0, 1)\n",
    "        noisy_image = tf.where(salt_pepper < self.prob / 2, 0.0, tensor)\n",
    "        noisy_image = tf.where(salt_pepper > 1 - self.prob / 2, 1.0, noisy_image)\n",
    "        return noisy_image\n",
    "\n",
    "class AddRayleighNoise(object):\n",
    "    def __init__(self, scale=0.26):\n",
    "        self.scale = scale\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        noise = tf.random.normal(tf.shape(tensor), mean=0.0, stddev=self.scale, dtype=tf.float32)\n",
    "        noisy_image = tensor + noise\n",
    "        noisy_image = tf.clip_by_value(noisy_image, 0.0, 1.0)\n",
    "        return noisy_image\n",
    "\n",
    "class AddSpeckleNoise(object):\n",
    "    def __init__(self, mean=0., std=0.5):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        noise = tf.random.normal(tf.shape(tensor), mean=self.mean, stddev=self.std, dtype=tf.float32)\n",
    "        noisy_tensor = tensor + tensor * noise\n",
    "        return noisy_tensor\n",
    "\n",
    "import random\n",
    "\n",
    "def noisy_generator(batches):\n",
    "    noise_types = ['gaussian', 'rayleigh', 'salt_and_pepper']\n",
    "    \n",
    "    for batch_x, batch_y in batches:\n",
    "        # Select a random noise type\n",
    "        noise_type = random.choice(noise_types)\n",
    "        \n",
    "        if noise_type == 'salt_and_pepper':\n",
    "            # Add Salt and Pepper Noise\n",
    "            noisy_transform = AddSaltAndPepperNoise(prob=0.3)\n",
    "        elif noise_type == 'gaussian':\n",
    "            # Add Gaussian Noise\n",
    "            noisy_transform = AddGaussianNoise(std=0.5)\n",
    "#         elif noise_type == 'speckle':\n",
    "            # Add Gaussian Noise\n",
    "#             noisy_transform = AddSpeckleNoise(std=0.5)\n",
    "        elif noise_type == 'rayleigh':\n",
    "            # Add Rayleigh Noise\n",
    "            noisy_transform = AddRayleighNoise(scale=0.1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid noise type. Choose from 'salt_and_pepper', 'gaussian', or 'rayleigh'.\")\n",
    "        \n",
    "        # Apply the noise transform\n",
    "        noisy_batch_x = tf.stack([noisy_transform(tensor) for tensor in batch_x])\n",
    "        \n",
    "        yield (noisy_batch_x, batch_y)\n",
    "\n",
    "\n",
    "\n",
    "import keras.layers as layers\n",
    "import keras.models as models\n",
    "from keras.initializers import orthogonal\n",
    "\n",
    "def Conv2DLayer(x, filters, kernel, strides, padding, block_id, kernel_init=orthogonal()):\n",
    "    prefix = f'block_{block_id}_'\n",
    "    x = layers.Conv2D(filters, kernel_size=kernel, strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_init, name=prefix+'conv')(x)\n",
    "    x = layers.ReLU(name=prefix+'relu')(x)\n",
    "    x = layers.Dropout(0.1, name=prefix+'drop')((x))\n",
    "    return x\n",
    "\n",
    "def Transpose_Conv2D(x, filters, kernel, strides, padding, block_id, kernel_init=orthogonal()):\n",
    "    prefix = f'block_{block_id}_'\n",
    "    x = layers.Conv2DTranspose(filters, kernel_size=kernel, strides=strides, padding=padding,\n",
    "                               kernel_initializer=kernel_init, name=prefix+'de-conv')(x)\n",
    "    x = layers.ReLU(name=prefix+'relu')(x)\n",
    "    x = layers.Dropout(0.1, name=prefix+'drop')((x))\n",
    "    return x\n",
    "\n",
    "def AutoEncdoer(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 256 x 256\n",
    "    conv1 = Conv2DLayer(inputs, 64, 3, strides=1, padding='same', block_id=1)\n",
    "    conv2 = Conv2DLayer(conv1, 64, 3, strides=2, padding='same', block_id=2)\n",
    "    \n",
    "    # 128 x 128\n",
    "    conv3 = Conv2DLayer(conv2, 128, 5, strides=2, padding='same', block_id=3)\n",
    "    \n",
    "    # 64 x 64\n",
    "    conv4 = Conv2DLayer(conv3, 128, 3, strides=1, padding='same', block_id=4)\n",
    "    conv5 = Conv2DLayer(conv4, 256, 5, strides=2, padding='same', block_id=5)\n",
    "    \n",
    "    # 32 x 32\n",
    "    conv6 = Conv2DLayer(conv5, 512, 3, strides=2, padding='same', block_id=6)\n",
    "    \n",
    "    # 16 x 16\n",
    "    deconv1 = Transpose_Conv2D(conv6, 512, 3, strides=2, padding='same', block_id=7)\n",
    "    \n",
    "    # 32 x 32\n",
    "    skip1 = layers.concatenate([deconv1, conv5], name='skip1')\n",
    "    conv7 = Conv2DLayer(skip1, 256, 3, strides=1, padding='same', block_id=8)\n",
    "    deconv2 = Transpose_Conv2D(conv7, 128, 3, strides=2, padding='same', block_id=9)\n",
    "    \n",
    "    # 64 x 64\n",
    "    skip2 = layers.concatenate([deconv2, conv3], name='skip2')\n",
    "    conv8 = Conv2DLayer(skip2, 128, 5, strides=1, padding='same', block_id=10)\n",
    "    deconv3 = Transpose_Conv2D(conv8, 64, 3, strides=2, padding='same', block_id=11)\n",
    "    \n",
    "    # 128 x 128\n",
    "    skip3 = layers.concatenate([deconv3, conv2], name='skip3')\n",
    "    conv9 = Conv2DLayer(skip3, 64, 5, strides=1, padding='same', block_id=12)\n",
    "    deconv4 = Transpose_Conv2D(conv9, 64, 3, strides=2, padding='same', block_id=13)\n",
    "    \n",
    "    # 256 x 256\n",
    "    skip3 = layers.concatenate([deconv4, conv1])\n",
    "    conv10 = layers.Conv2D(3, 3, strides=1, padding='same', activation='sigmoid',\n",
    "                       kernel_initializer=orthogonal(), name='final_conv')(skip3)\n",
    "\n",
    "    \n",
    "    return models.Model(inputs=inputs, outputs=conv10)\n",
    "#     decoded = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(conv10)\n",
    "    \n",
    "#     return models.Model(inputs=inputs, outputs=decoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_path = '/kaggle/input/aaaaaaaaaaa/owndataset'\n",
    "\n",
    "\n",
    "                                            \n",
    "test_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "test_batches = test_datagen.flow_from_directory(\n",
    "    dataset_path ,\n",
    "    **data_flow_args)\n",
    "\n",
    "test_noisy_batches = noisy_generator(test_batches)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X, y = next(test_noisy_batches)\n",
    "\n",
    "\n",
    "\n",
    "score = model.evaluate(X, y, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "decoded_imgs = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(**data_gen_args)\n",
    "val_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "train_batches = train_datagen.flow_from_directory(\n",
    "    dataset_path + '/train',\n",
    "    **data_flow_args)\n",
    "\n",
    "val_batches = val_datagen.flow_from_directory(\n",
    "    dataset_path + '/val',\n",
    "    **data_flow_args)\n",
    "\n",
    "\n",
    "train_noisy_batches = noisy_generator(train_batches)\n",
    "val_noisy_batches = noisy_generator(val_batches)\n",
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "model = AutoEncdoer((*input_shape, 3))\n",
    "# model_opt = SGD(lr=0.005, decay=1-0.995, momentum=0.7, nesterov=False)\n",
    "model_opt = Adam(learning_rate=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "def psnr(y_true, y_pred):\n",
    "    return tf.image.psnr(y_true, y_pred, max_val=1.0)\n",
    "\n",
    "def ssim(y_true, y_pred):\n",
    "    return tf.image.ssim(y_true, y_pred, max_val=1.0)\n",
    "\n",
    "model.compile(optimizer=model_opt, loss='mse', metrics=['accuracy', psnr, ssim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def tv_loss(y_true, y_pred):\n",
    "    # Calculate the total variation loss\n",
    "    dy = tf.abs(y_pred[:, 1:, :, :] - y_pred[:, :-1, :, :])\n",
    "    dx = tf.abs(y_pred[:, :, 1:, :] - y_pred[:, :, :-1, :])\n",
    "    tv_loss = tf.reduce_mean(dx) + tf.reduce_mean(dy)\n",
    "    \n",
    "    # Define your main loss function (e.g., MSE)\n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    \n",
    "    # Combine the two losses with a weighting factor\n",
    "    alpha = 0.1  # Weighting factor for TV regularization\n",
    "    total_loss = mse_loss + alpha * tv_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "# model.compile(optimizer=model_opt, loss=tv_loss, metrics=['accuracy'])\n",
    "# modelchk = keras.callbacks.ModelCheckpoint(\n",
    "#                                       monitor='accuracy',\n",
    "#                                       verbose=1,\n",
    "#                                       save_best_only=True,\n",
    "#                                       save_weights_only=False,\n",
    "#                                       mode='auto',\n",
    "#                                       save_freq=2)\n",
    "# Define the filepath where the model will be saved\n",
    "saved_model_path = './content/saved_models/my_model.keras'\n",
    "\n",
    "# Define ModelCheckpoint callback\n",
    "modelchk = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=saved_model_path,  # specify the filepath here\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    save_freq=2\n",
    ")\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=P_LOGS,\n",
    "                                          histogram_freq=0,\n",
    "                                          write_graph=True,\n",
    "                                          write_images=True)\n",
    "\n",
    "csv_logger = keras.callbacks.CSVLogger(f'{P_LOGS}/keras_log.csv',\n",
    "                                       append=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_noisy_batches,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: val_noisy_batches,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "epochs=100\n",
    "\n",
    "history=model.fit(train_dataset,\n",
    "          steps_per_epoch=train_batches.samples // batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1, \n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=train_batches.samples // batch_size,\n",
    "          callbacks=[modelchk, tensorboard, csv_logger])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_path = '/kaggle/input/aaaaaaaaaaa/owndataset'\n",
    "\n",
    "\n",
    "                                            \n",
    "test_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "test_batches = test_datagen.flow_from_directory(\n",
    "    dataset_path ,\n",
    "    **data_flow_args)\n",
    "\n",
    "test_noisy_batches = noisy_generator(test_batches)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X, y = next(test_noisy_batches)\n",
    "\n",
    "\n",
    "\n",
    "score = model.evaluate(X, y, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "decoded_imgs = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "for i in range(len(y)):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Display the input image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(X[i])\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Display the output (decoded) image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.title('Output (Decoded) Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Calculate PSNR\n",
    "    psnr_val = tf.image.psnr(y[i], decoded_imgs[i], max_val=1.0)\n",
    "\n",
    "    # Calculate SSIM\n",
    "    ssim_val = tf.image.ssim(y[i], decoded_imgs[i], max_val=1.0)\n",
    "\n",
    "    # Display PSNR and SSIM\n",
    "    plt.text(1.5, 0.5, f\"PSNR: {psnr_val.numpy():.4f}\\nSSIM: {ssim_val.numpy():.4f}\", \n",
    "             horizontalalignment='center', verticalalignment='center', \n",
    "             fontsize=12, color='black', transform=plt.gca().transAxes)\n",
    "\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
